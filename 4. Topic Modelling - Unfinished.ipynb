{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8017c883",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8004aa",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #1 (All Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef8e1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aadit</th>\n",
       "      <th>aakash</th>\n",
       "      <th>aampt</th>\n",
       "      <th>aapl</th>\n",
       "      <th>aapsky</th>\n",
       "      <th>aarna</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aatmanirbhar</th>\n",
       "      <th>aave</th>\n",
       "      <th>aavegotchi</th>\n",
       "      <th>...</th>\n",
       "      <th>zuckerbergthese</th>\n",
       "      <th>zuddl</th>\n",
       "      <th>zuhaib</th>\n",
       "      <th>zuper</th>\n",
       "      <th>zurichbased</th>\n",
       "      <th>zwc</th>\n",
       "      <th>zymrat</th>\n",
       "      <th>zynga</th>\n",
       "      <th>zynn</th>\n",
       "      <th>zypp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aditya</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daniel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepti</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kul</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miguel</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roehl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samreen</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shravanth</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stefanie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tia bot</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 20954 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           aadit  aakash  aampt  aapl  aapsky  aarna  aaron  aatmanirbhar  \\\n",
       "aditya         0       0      0     0       0      0      0             0   \n",
       "daniel         0       0      0     0       0      0      0             0   \n",
       "deepti         4       1      0     0       0      0      2             0   \n",
       "kul            0       0      0     0       0      0      0             0   \n",
       "miguel         0       1      0     0       0      1      0             0   \n",
       "roehl          0       0      0     0       1      0      0             0   \n",
       "samreen        0       0      1     0       0      0      0             1   \n",
       "shravanth      1       0      0     1       0      0      0             0   \n",
       "stefanie       0       0      0     0       0      0      0             0   \n",
       "tia bot        0       0      0     0       0      0      0             0   \n",
       "\n",
       "           aave  aavegotchi  ...  zuckerbergthese  zuddl  zuhaib  zuper  \\\n",
       "aditya        0           0  ...                0      1       0      0   \n",
       "daniel        0           0  ...                0      0       0      0   \n",
       "deepti        0           0  ...                0      0       0      0   \n",
       "kul           1           1  ...                0      0       0      0   \n",
       "miguel        0           0  ...                0      0       0      0   \n",
       "roehl         0           0  ...                0      0       0      0   \n",
       "samreen       0           0  ...                0      0       1      1   \n",
       "shravanth     0           0  ...                0      0       0      0   \n",
       "stefanie      0           0  ...                1      0       0      0   \n",
       "tia bot       0           0  ...                0      0       0      0   \n",
       "\n",
       "           zurichbased  zwc  zymrat  zynga  zynn  zypp  \n",
       "aditya               0    0       0      0     0     0  \n",
       "daniel               0    0       0      0     0     0  \n",
       "deepti               1    2       0      0     0     1  \n",
       "kul                  0    0       0      0     0     0  \n",
       "miguel               0    0       1      0     0     0  \n",
       "roehl                0    0       0      0     0     0  \n",
       "samreen              0    0       0      0     1     0  \n",
       "shravanth            1    0       0      1     0     0  \n",
       "stefanie             0    0       0      0     0     0  \n",
       "tia bot              0    0       0      0     0     0  \n",
       "\n",
       "[10 rows x 20954 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in our document-term matrix\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('dtm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87241145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules for LDA with gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2368292d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aditya</th>\n",
       "      <th>daniel</th>\n",
       "      <th>deepti</th>\n",
       "      <th>kul</th>\n",
       "      <th>miguel</th>\n",
       "      <th>roehl</th>\n",
       "      <th>samreen</th>\n",
       "      <th>shravanth</th>\n",
       "      <th>stefanie</th>\n",
       "      <th>tia bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aadit</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aakash</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aampt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aapl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aapsky</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        aditya  daniel  deepti  kul  miguel  roehl  samreen  shravanth  \\\n",
       "aadit        0       0       4    0       0      0        0          1   \n",
       "aakash       0       0       1    0       1      0        0          0   \n",
       "aampt        0       0       0    0       0      0        1          0   \n",
       "aapl         0       0       0    0       0      0        0          1   \n",
       "aapsky       0       0       0    0       0      1        0          0   \n",
       "\n",
       "        stefanie  tia bot  \n",
       "aadit          0        0  \n",
       "aakash         0        0  \n",
       "aampt          0        0  \n",
       "aapl           0        0  \n",
       "aapsky         0        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the required inputs is a term-document matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc9b1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a7fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fa75258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"india\" + 0.003*\"ventures\" + 0.003*\"firms\" + 0.003*\"photo\" + 0.003*\"companies\" + 0.003*\"services\" + 0.003*\"fund\" + 0.003*\"led\" + 0.003*\"plans\" + 0.003*\"data\"'),\n",
       " (1,\n",
       "  '0.003*\"companies\" + 0.003*\"global\" + 0.003*\"firms\" + 0.003*\"india\" + 0.003*\"market\" + 0.003*\"ventures\" + 0.002*\"singapore\" + 0.002*\"led\" + 0.002*\"group\" + 0.002*\"services\"')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414f905b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.000*\"india\" + 0.000*\"ecommerce\" + 0.000*\"global\" + 0.000*\"services\" + 0.000*\"led\" + 0.000*\"fintech\" + 0.000*\"ceo\" + 0.000*\"investment\" + 0.000*\"cofounder\" + 0.000*\"fund\"'),\n",
       " (1,\n",
       "  '0.003*\"india\" + 0.003*\"ecommerce\" + 0.003*\"firms\" + 0.003*\"ventures\" + 0.003*\"companies\" + 0.003*\"market\" + 0.003*\"led\" + 0.003*\"ceo\" + 0.002*\"services\" + 0.002*\"financial\"'),\n",
       " (2,\n",
       "  '0.005*\"india\" + 0.003*\"ventures\" + 0.003*\"firms\" + 0.003*\"companies\" + 0.003*\"global\" + 0.003*\"services\" + 0.003*\"led\" + 0.003*\"market\" + 0.003*\"plans\" + 0.003*\"photo\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 3\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fdde183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"india\" + 0.003*\"ceo\" + 0.003*\"companies\" + 0.003*\"singapore\" + 0.002*\"services\" + 0.002*\"photo\" + 0.002*\"team\" + 0.002*\"ventures\" + 0.002*\"help\" + 0.002*\"firms\"'),\n",
       " (1,\n",
       "  '0.000*\"india\" + 0.000*\"ventures\" + 0.000*\"services\" + 0.000*\"photo\" + 0.000*\"market\" + 0.000*\"firms\" + 0.000*\"global\" + 0.000*\"companies\" + 0.000*\"users\" + 0.000*\"financial\"'),\n",
       " (2,\n",
       "  '0.004*\"firms\" + 0.004*\"india\" + 0.003*\"companies\" + 0.003*\"market\" + 0.003*\"ventures\" + 0.003*\"services\" + 0.003*\"led\" + 0.003*\"data\" + 0.003*\"global\" + 0.003*\"group\"'),\n",
       " (3,\n",
       "  '0.006*\"india\" + 0.004*\"ventures\" + 0.003*\"fintech\" + 0.003*\"global\" + 0.003*\"plans\" + 0.003*\"users\" + 0.003*\"photo\" + 0.003*\"crypto\" + 0.003*\"indonesia\" + 0.003*\"use\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 4\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8785a0",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #2 (Nouns Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f390ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21ca77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2271358f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aditya</th>\n",
       "      <td>Aditya Hadi Pratama</td>\n",
       "      <td>cialfo a singaporebased edtech startup has rai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daniel</th>\n",
       "      <td>Daniel Rouquette</td>\n",
       "      <td>this is the daily news roundup delivered every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepti</th>\n",
       "      <td>Deepti Sri</td>\n",
       "      <td>singaporebased insurtech firm igloo has raised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kul</th>\n",
       "      <td>Kul Bhushan</td>\n",
       "      <td>indiabased loco a streaming platform for video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miguel</th>\n",
       "      <td>Miguel Cordon</td>\n",
       "      <td>singaporebased silent eight a startup offering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roehl</th>\n",
       "      <td>Roehl Niño Bautista</td>\n",
       "      <td>amazon web services aws and the malaysian gove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samreen</th>\n",
       "      <td>Samreen Ahmad</td>\n",
       "      <td>startups in india including loco and kuku fm r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shravanth</th>\n",
       "      <td>Shravanth Vijayakumar</td>\n",
       "      <td>sign up for the daily newsletter sent exclusiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stefanie</th>\n",
       "      <td>Stefanie Yeo</td>\n",
       "      <td>as part of tech in asias  international womens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tia bot</th>\n",
       "      <td>TIA Bot</td>\n",
       "      <td>southeast asia has seen its fair share of mamp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     author_name  \\\n",
       "aditya       Aditya Hadi Pratama   \n",
       "daniel          Daniel Rouquette   \n",
       "deepti                Deepti Sri   \n",
       "kul                  Kul Bhushan   \n",
       "miguel             Miguel Cordon   \n",
       "roehl        Roehl Niño Bautista   \n",
       "samreen            Samreen Ahmad   \n",
       "shravanth  Shravanth Vijayakumar   \n",
       "stefanie            Stefanie Yeo   \n",
       "tia bot                  TIA Bot   \n",
       "\n",
       "                                                     content  \n",
       "aditya     cialfo a singaporebased edtech startup has rai...  \n",
       "daniel     this is the daily news roundup delivered every...  \n",
       "deepti     singaporebased insurtech firm igloo has raised...  \n",
       "kul        indiabased loco a streaming platform for video...  \n",
       "miguel     singaporebased silent eight a startup offering...  \n",
       "roehl      amazon web services aws and the malaysian gove...  \n",
       "samreen    startups in india including loco and kuku fm r...  \n",
       "shravanth  sign up for the daily newsletter sent exclusiv...  \n",
       "stefanie   as part of tech in asias  international womens...  \n",
       "tia bot    southeast asia has seen its fair share of mamp...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data, before the CountVectorizer step\n",
    "data_clean = pd.read_pickle('corpus.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6845e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aditya</th>\n",
       "      <td>edtech startup series b funding investment fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daniel</th>\n",
       "      <td>news roundup email tech website newsletter tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepti</th>\n",
       "      <td>firm igloo series b funding round vc firm cath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kul</th>\n",
       "      <td>streaming platform video games rupees series f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miguel</th>\n",
       "      <td>startup offering compliance platforms institut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roehl</th>\n",
       "      <td>amazon web services aws government cloud frame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samreen</th>\n",
       "      <td>startups loco fm funding day investorsheres sn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shravanth</th>\n",
       "      <td>sign newsletter subscribers topics tech startu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stefanie</th>\n",
       "      <td>part tech womens day campaign bias survey foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tia bot</th>\n",
       "      <td>southeast asia share deals years moves others ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     content\n",
       "aditya     edtech startup series b funding investment fir...\n",
       "daniel     news roundup email tech website newsletter tec...\n",
       "deepti     firm igloo series b funding round vc firm cath...\n",
       "kul        streaming platform video games rupees series f...\n",
       "miguel     startup offering compliance platforms institut...\n",
       "roehl      amazon web services aws government cloud frame...\n",
       "samreen    startups loco fm funding day investorsheres sn...\n",
       "shravanth  sign newsletter subscribers topics tech startu...\n",
       "stefanie   part tech womens day campaign bias survey foun...\n",
       "tia bot    southeast asia share deals years moves others ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns = pd.DataFrame(data_clean.content.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a931f163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\miniconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aadit</th>\n",
       "      <th>aakash</th>\n",
       "      <th>aapl</th>\n",
       "      <th>aapsky</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abdullah</th>\n",
       "      <th>abhay</th>\n",
       "      <th>abhimanyu</th>\n",
       "      <th>...</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuckerbergs</th>\n",
       "      <th>zuckerbergthese</th>\n",
       "      <th>zuddl</th>\n",
       "      <th>zuhaib</th>\n",
       "      <th>zuper</th>\n",
       "      <th>zymrat</th>\n",
       "      <th>zynga</th>\n",
       "      <th>zynn</th>\n",
       "      <th>zypp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aditya</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daniel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepti</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kul</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miguel</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roehl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samreen</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shravanth</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stefanie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tia bot</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 13022 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           aadit  aakash  aapl  aapsky  aaron  ab  abacus  abdullah  abhay  \\\n",
       "aditya         0       0     0       0      0   0       0         0      0   \n",
       "daniel         0       0     0       0      0   0       0         0      0   \n",
       "deepti         4       0     0       0      1   0       0         0      1   \n",
       "kul            0       0     0       0      0   0       0         1      0   \n",
       "miguel         0       1     0       0      0   1       0         0      0   \n",
       "roehl          0       0     0       1      0   0       0         0      0   \n",
       "samreen        0       0     0       0      0   0       2         0      0   \n",
       "shravanth      1       0     1       0      0   0       0         0      0   \n",
       "stefanie       0       0     0       0      0   0       0         0      0   \n",
       "tia bot        0       0     0       0      0   0       0         0      0   \n",
       "\n",
       "           abhimanyu  ...  zuckerberg  zuckerbergs  zuckerbergthese  zuddl  \\\n",
       "aditya             0  ...           0            0                0      1   \n",
       "daniel             0  ...           1            0                0      0   \n",
       "deepti             0  ...           1            0                0      0   \n",
       "kul                0  ...           0            0                0      0   \n",
       "miguel             0  ...           0            0                0      0   \n",
       "roehl              0  ...           0            0                0      0   \n",
       "samreen            2  ...           0            0                0      0   \n",
       "shravanth          0  ...           1            1                0      0   \n",
       "stefanie           0  ...           0            0                1      0   \n",
       "tia bot            0  ...           0            0                0      0   \n",
       "\n",
       "           zuhaib  zuper  zymrat  zynga  zynn  zypp  \n",
       "aditya          0      0       0      0     0     0  \n",
       "daniel          0      0       0      0     0     0  \n",
       "deepti          0      0       0      0     0     1  \n",
       "kul             0      0       0      0     0     0  \n",
       "miguel          0      0       1      0     0     0  \n",
       "roehl           0      0       0      0     0     0  \n",
       "samreen         1      1       0      0     1     0  \n",
       "shravanth       0      0       0      1     0     0  \n",
       "stefanie        0      0       0      0     0     0  \n",
       "tia bot         0      0       0      0     0     0  \n",
       "\n",
       "[10 rows x 13022 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Re-add the additional stop words since we are recreating the document-term matrix\n",
    "add_stop_words = ['million', 'company', 'raised', 'round', 'said', 'year', 'day', 'list', 'startups',\n",
    "                  'weve', 'lists', 'past', 'photo', 'platform', 'led', 'theyve', 'herewhich']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.content)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c696e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0473e5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"firm\" + 0.009*\"startup\" + 0.008*\"credit\" + 0.007*\"tech\" + 0.007*\"capital\" + 0.007*\"funding\" + 0.006*\"asia\" + 0.006*\"series\" + 0.005*\"investors\" + 0.005*\"ventures\"'),\n",
       " (1,\n",
       "  '0.008*\"firm\" + 0.008*\"credit\" + 0.008*\"tech\" + 0.006*\"investors\" + 0.006*\"firms\" + 0.006*\"asia\" + 0.006*\"companies\" + 0.006*\"capital\" + 0.005*\"funding\" + 0.005*\"data\"')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=2, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3750fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.000*\"credit\" + 0.000*\"ventures\" + 0.000*\"firm\" + 0.000*\"startup\" + 0.000*\"tech\" + 0.000*\"asia\" + 0.000*\"investors\" + 0.000*\"firms\" + 0.000*\"capital\" + 0.000*\"series\"'),\n",
       " (1,\n",
       "  '0.008*\"credit\" + 0.007*\"tech\" + 0.007*\"firm\" + 0.007*\"investors\" + 0.006*\"data\" + 0.006*\"funding\" + 0.006*\"asia\" + 0.006*\"companies\" + 0.006*\"firms\" + 0.006*\"india\"'),\n",
       " (2,\n",
       "  '0.011*\"firm\" + 0.009*\"credit\" + 0.009*\"startup\" + 0.008*\"tech\" + 0.008*\"capital\" + 0.006*\"funding\" + 0.006*\"asia\" + 0.006*\"investors\" + 0.006*\"series\" + 0.006*\"ventures\"')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 3 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=3, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b25d41bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"firm\" + 0.009*\"tech\" + 0.008*\"credit\" + 0.008*\"startup\" + 0.008*\"capital\" + 0.006*\"asia\" + 0.006*\"investors\" + 0.005*\"funding\" + 0.005*\"market\" + 0.005*\"companies\"'),\n",
       " (1,\n",
       "  '0.010*\"data\" + 0.008*\"firms\" + 0.008*\"firm\" + 0.008*\"credit\" + 0.008*\"investors\" + 0.007*\"companies\" + 0.007*\"tech\" + 0.007*\"funding\" + 0.007*\"asia\" + 0.005*\"series\"'),\n",
       " (2,\n",
       "  '0.010*\"firm\" + 0.009*\"startup\" + 0.009*\"funding\" + 0.009*\"credit\" + 0.007*\"ventures\" + 0.006*\"series\" + 0.006*\"tech\" + 0.006*\"capital\" + 0.005*\"indonesia\" + 0.005*\"asia\"'),\n",
       " (3,\n",
       "  '0.001*\"firm\" + 0.001*\"credit\" + 0.000*\"ventures\" + 0.000*\"asia\" + 0.000*\"tech\" + 0.000*\"capital\" + 0.000*\"funding\" + 0.000*\"investors\" + 0.000*\"series\" + 0.000*\"startup\"')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb54c8",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #3 (Nouns and Adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3844461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd8b28f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aditya</th>\n",
       "      <td>singaporebased edtech startup series b funding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daniel</th>\n",
       "      <td>daily news roundup everyday email tech asia we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepti</th>\n",
       "      <td>insurtech firm igloo series b funding round gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kul</th>\n",
       "      <td>streaming platform video games rupees series f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miguel</th>\n",
       "      <td>silent startup offering compliance platforms f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roehl</th>\n",
       "      <td>amazon web services aws malaysian government n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samreen</th>\n",
       "      <td>startups india loco fm least funding past day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shravanth</th>\n",
       "      <td>sign daily newsletter premium subscribers big ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stefanie</th>\n",
       "      <td>part tech asias international womens day campa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tia bot</th>\n",
       "      <td>southeast asia fair share mampa deals years bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     content\n",
       "aditya     singaporebased edtech startup series b funding...\n",
       "daniel     daily news roundup everyday email tech asia we...\n",
       "deepti     insurtech firm igloo series b funding round gl...\n",
       "kul        streaming platform video games rupees series f...\n",
       "miguel     silent startup offering compliance platforms f...\n",
       "roehl      amazon web services aws malaysian government n...\n",
       "samreen    startups india loco fm least funding past day ...\n",
       "shravanth  sign daily newsletter premium subscribers big ...\n",
       "stefanie   part tech asias international womens day campa...\n",
       "tia bot    southeast asia fair share mampa deals years bl..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns_adj = pd.DataFrame(data_clean.content.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c3d34b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\miniconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aadit</th>\n",
       "      <th>aakash</th>\n",
       "      <th>aampt</th>\n",
       "      <th>aapl</th>\n",
       "      <th>aapsky</th>\n",
       "      <th>aarna</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aatmanirbhar</th>\n",
       "      <th>aavegotchi</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>zuckerbergs</th>\n",
       "      <th>zuckerbergthese</th>\n",
       "      <th>zuddl</th>\n",
       "      <th>zuhaib</th>\n",
       "      <th>zuper</th>\n",
       "      <th>zurichbased</th>\n",
       "      <th>zymrat</th>\n",
       "      <th>zynga</th>\n",
       "      <th>zynn</th>\n",
       "      <th>zypp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aditya</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daniel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepti</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kul</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miguel</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roehl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samreen</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shravanth</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stefanie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tia bot</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 16088 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           aadit  aakash  aampt  aapl  aapsky  aarna  aaron  aatmanirbhar  \\\n",
       "aditya         0       0      0     0       0      0      0             0   \n",
       "daniel         0       0      0     0       0      0      0             0   \n",
       "deepti         4       1      0     0       0      0      1             0   \n",
       "kul            0       0      0     0       0      0      0             0   \n",
       "miguel         0       1      0     0       0      1      0             0   \n",
       "roehl          0       0      0     0       1      0      0             0   \n",
       "samreen        0       0      1     0       0      0      0             1   \n",
       "shravanth      1       0      0     1       0      0      0             0   \n",
       "stefanie       0       0      0     0       0      0      0             0   \n",
       "tia bot        0       0      0     0       0      0      0             0   \n",
       "\n",
       "           aavegotchi  ab  ...  zuckerbergs  zuckerbergthese  zuddl  zuhaib  \\\n",
       "aditya              0   0  ...            0                0      1       0   \n",
       "daniel              0   0  ...            0                0      0       0   \n",
       "deepti              0   0  ...            0                0      0       0   \n",
       "kul                 1   0  ...            0                0      0       0   \n",
       "miguel              0   1  ...            0                0      0       0   \n",
       "roehl               0   0  ...            0                0      0       0   \n",
       "samreen             0   1  ...            0                0      0       1   \n",
       "shravanth           0   0  ...            1                0      0       0   \n",
       "stefanie            0   0  ...            0                1      0       0   \n",
       "tia bot             0   0  ...            0                0      0       0   \n",
       "\n",
       "           zuper  zurichbased  zymrat  zynga  zynn  zypp  \n",
       "aditya         0            0       0      0     0     0  \n",
       "daniel         0            0       0      0     0     0  \n",
       "deepti         0            1       0      0     0     1  \n",
       "kul            0            0       0      0     0     0  \n",
       "miguel         0            0       1      0     0     0  \n",
       "roehl          0            0       0      0     0     0  \n",
       "samreen        1            0       0      0     1     0  \n",
       "shravanth      0            1       0      1     0     0  \n",
       "stefanie       0            0       0      0     0     0  \n",
       "tia bot        0            0       0      0     0     0  \n",
       "\n",
       "[10 rows x 16088 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.content)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9dd286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dccf60a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"companys\" + 0.003*\"local\" + 0.002*\"brands\" + 0.002*\"shopee\" + 0.002*\"live\" + 0.002*\"founders\" + 0.002*\"autogenerated\" + 0.002*\"updated\" + 0.001*\"healthcare\" + 0.001*\"director\"'),\n",
       " (1,\n",
       "  '0.003*\"companys\" + 0.003*\"brands\" + 0.003*\"premium\" + 0.003*\"local\" + 0.002*\"founders\" + 0.002*\"newsletter\" + 0.002*\"biggest\" + 0.002*\"inbox\" + 0.002*\"subscribers\" + 0.001*\"participation\"')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5457d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"companys\" + 0.003*\"local\" + 0.003*\"brands\" + 0.003*\"founders\" + 0.002*\"director\" + 0.002*\"fraud\" + 0.002*\"marketing\" + 0.002*\"live\" + 0.002*\"dollar\" + 0.001*\"undisclosed\"'),\n",
       " (1,\n",
       "  '0.005*\"premium\" + 0.004*\"newsletter\" + 0.003*\"inbox\" + 0.003*\"biggest\" + 0.002*\"subscribers\" + 0.002*\"companys\" + 0.002*\"everyday\" + 0.002*\"timmy\" + 0.002*\"stories\" + 0.002*\"comprehensive\"'),\n",
       " (2,\n",
       "  '0.004*\"statement\" + 0.003*\"companys\" + 0.003*\"local\" + 0.003*\"indonesiabased\" + 0.002*\"brands\" + 0.002*\"participation\" + 0.002*\"founders\" + 0.002*\"undisclosed\" + 0.002*\"assets\" + 0.002*\"job\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 3 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c243a2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"premium\" + 0.003*\"newsletter\" + 0.003*\"companys\" + 0.002*\"brands\" + 0.002*\"inbox\" + 0.002*\"biggest\" + 0.002*\"subscribers\" + 0.002*\"local\" + 0.002*\"founders\" + 0.002*\"everyday\"'),\n",
       " (1,\n",
       "  '0.005*\"fraud\" + 0.005*\"female\" + 0.004*\"founders\" + 0.003*\"victoria\" + 0.002*\"premium\" + 0.002*\"tokopedia\" + 0.002*\"youre\" + 0.002*\"support\" + 0.002*\"newsletter\" + 0.002*\"young\"'),\n",
       " (2,\n",
       "  '0.004*\"companys\" + 0.004*\"local\" + 0.003*\"statement\" + 0.003*\"brands\" + 0.003*\"shopee\" + 0.002*\"founders\" + 0.002*\"live\" + 0.002*\"indonesiabased\" + 0.002*\"assets\" + 0.002*\"participation\"'),\n",
       " (3,\n",
       "  '0.003*\"brands\" + 0.003*\"companys\" + 0.003*\"local\" + 0.002*\"founders\" + 0.002*\"autogenerated\" + 0.002*\"updated\" + 0.002*\"dollar\" + 0.002*\"director\" + 0.002*\"chief\" + 0.002*\"dark\"')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc092ddd",
   "metadata": {},
   "source": [
    "# Identify Topics in Each Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0f9ee92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.000*\"picture\" + 0.000*\"trends\" + 0.000*\"serves\" + 0.000*\"infographics\" + 0.000*\"relative\" + 0.000*\"macro\" + 0.000*\"answer\" + 0.000*\"japanbased\" + 0.000*\"usvolopayfinancial\" + 0.000*\"bhdxora\"'),\n",
       " (1,\n",
       "  '0.004*\"premium\" + 0.003*\"founders\" + 0.003*\"biggest\" + 0.003*\"female\" + 0.003*\"fraud\" + 0.002*\"brands\" + 0.002*\"newsletter\" + 0.002*\"local\" + 0.002*\"companys\" + 0.002*\"subscribers\"'),\n",
       " (2,\n",
       "  '0.004*\"newsletter\" + 0.003*\"companys\" + 0.003*\"premium\" + 0.003*\"local\" + 0.002*\"shopee\" + 0.002*\"timmy\" + 0.002*\"live\" + 0.002*\"brands\" + 0.002*\"inbox\" + 0.002*\"seas\"'),\n",
       " (3,\n",
       "  '0.004*\"companys\" + 0.004*\"brands\" + 0.003*\"local\" + 0.003*\"founders\" + 0.002*\"statement\" + 0.002*\"dollar\" + 0.002*\"participation\" + 0.002*\"chief\" + 0.002*\"director\" + 0.002*\"undisclosed\"')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final LDA model (for now)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=80)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cfc0f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'aditya'),\n",
       " (1, 'daniel'),\n",
       " (3, 'deepti'),\n",
       " (1, 'kul'),\n",
       " (3, 'miguel'),\n",
       " (3, 'roehl'),\n",
       " (2, 'samreen'),\n",
       " (2, 'shravanth'),\n",
       " (1, 'stefanie'),\n",
       " (3, 'tia bot')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at which topics each transcript contains\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
